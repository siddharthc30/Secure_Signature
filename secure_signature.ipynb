{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "secure_signature.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPBTM456YNISgu21w+pg/qS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siddharthc30/Secure_Signature/blob/main/secure_signature.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dDPc9wLqv6E"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "H1Y6mhE5q7IZ",
        "outputId": "ecc3023a-4c7b-4cef-8681-68b18633e696"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ea798da5-47c8-4c8e-bedc-734d5c089dd9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ea798da5-47c8-4c8e-bedc-734d5c089dd9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle (1).json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"siddharthc30\",\"key\":\"09b5501351cdb4f0a0ad4b15b33d26ec\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QmA-01SMrGbt",
        "outputId": "df367b48-9b97-497b-8d8e-b8e6c1180caa"
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osimgnNVrO4S"
      },
      "source": [
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L665Oyu4rR4o",
        "outputId": "f303dd61-7077-4c2b-b9ef-f9398a932ad0"
      },
      "source": [
        "! kaggle datasets download -d robinreni/signature-verification-dataset"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "signature-verification-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcA5iyuRrkE0"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile('signature-verification-dataset.zip','r') as zip:\n",
        "  zip.extractall()\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz9G7ZrXsMdW"
      },
      "source": [
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from torch.optim import lr_scheduler\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps    \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd "
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZqaiZcYs9Bl"
      },
      "source": [
        "class SiameseNetworkDataset():\n",
        "    \n",
        "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
        "        # used to prepare the labels and images path\n",
        "        self.training_df=pd.read_csv(training_csv)\n",
        "        self.training_df.columns =[\"image1\",\"image2\",\"label\"]\n",
        "        self.training_dir = training_dir    \n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        # getting the image path\n",
        "        image1_path=os.path.join(self.training_dir,self.training_df.iat[index,0])\n",
        "        image2_path=os.path.join(self.training_dir,self.training_df.iat[index,1])\n",
        "        \n",
        "        \n",
        "        # Loading the image\n",
        "        img0 = Image.open(image1_path)\n",
        "        img1 = Image.open(image2_path)\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "        \n",
        "        # Apply image transformations\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        \n",
        "        return img0, img1 , torch.from_numpy(np.array([int(self.training_df.iat[index,2])],dtype=np.float32))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.training_df)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz5fh3QEtHl_"
      },
      "source": [
        "training_dir=\"sign_data/sign_data/train\"\n",
        "training_csv=\"sign_data/sign_data/train_data.csv\"\n",
        "testing_csv=\"sign_data/sign_data/test_data.csv\"\n",
        "testing_dir=\"sign_data/sign_data/test\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgJn6Sp6tR-3"
      },
      "source": [
        "siamese_dataset = SiameseNetworkDataset(training_csv,training_dir,\n",
        "                                        transform=transforms.Compose([transforms.Resize((105,105)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ]))"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhWmlrhOuW98"
      },
      "source": [
        "class Config():\n",
        "    training_dir = \"sign_data/sign_data/train\"\n",
        "    testing_dir = \"sign_data/sign_data/test\"\n",
        "    train_batch_size = 32\n",
        "    train_number_epochs = 20"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8ShWf2GtZ29"
      },
      "source": [
        "vis_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        batch_size=8)\n",
        "dataiter = iter(vis_dataloader)\n",
        "\n",
        "\n",
        "example_batch = next(dataiter)\n",
        "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
        "#imshow(torchvision.utils.make_grid(concatenated))\n",
        "#print(example_batch[2].numpy())"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5CVf2fRtmoD"
      },
      "source": [
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        \n",
        "        # Setting up the Sequential of CNN Layers\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout2d(p=0.3),\n",
        "\n",
        "        )\n",
        "        \n",
        "        # Defining the fully connected layers\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=0.5),\n",
        "            \n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(128,2))\n",
        "        \n",
        "  \n",
        "  \n",
        "    def forward_once(self, x):\n",
        "        # Forward pass \n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2):\n",
        "        # forward pass of input 1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # forward pass of input 2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrxKT3v8t1Rs"
      },
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "        return loss_contrastive"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpNJ-_cmuI1E",
        "outputId": "4d05f792-b4be-4df9-ede9-97e772662fcc"
      },
      "source": [
        "train_dataloader = DataLoader(siamese_dataset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=Config.train_batch_size)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qxfw-HvwuMh0",
        "outputId": "5178b5fa-378d-4e8a-bb7a-a59badb53832"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    print('Yes')\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Yes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzFuC_PBuhla"
      },
      "source": [
        "net = SiameseNetwork().cuda()\n",
        "# Decalre Loss Function\n",
        "criterion = ContrastiveLoss()\n",
        "# Declare Optimizer\n",
        "optimizer = optim.RMSprop(net.parameters(), lr=1e-4, alpha=0.99, eps=1e-8, weight_decay=0.0005, momentum=0.9)"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2t9kkdwukJr"
      },
      "source": [
        "def train():\n",
        "    counter = []\n",
        "    loss_history = [] \n",
        "    iteration_number= 0\n",
        "    \n",
        "    for epoch in range(0,Config.train_number_epochs):\n",
        "        for i, data in enumerate(train_dataloader,0):\n",
        "            img0, img1 , label = data\n",
        "            img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
        "            optimizer.zero_grad()\n",
        "            output1,output2 = net(img0,img1)\n",
        "            loss_contrastive = criterion(output1,output2,label)\n",
        "            loss_contrastive.backward()\n",
        "            optimizer.step()\n",
        "            if i %50 == 0 :\n",
        "                print(\"Epoch number {}\\n Current loss {}\\n\".format(epoch,loss_contrastive.item()))\n",
        "                iteration_number +=10\n",
        "                counter.append(iteration_number)\n",
        "                loss_history.append(loss_contrastive.item())\n",
        "    return net"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBB4cVXfuy-e",
        "outputId": "9be5c6c0-9e17-428e-e77c-a43c23b2c2d0"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# Train the model\n",
        "model = train()\n",
        "torch.save(model.state_dict(), \"model.pt\")\n",
        "print(\"Model Saved Successfully\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch number 0\n",
            " Current loss 1.2452688217163086\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.1876115798950195\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.2080659866333008\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.1296849250793457\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.1695053577423096\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.648238182067871\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.3905600309371948\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 0.8650287389755249\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.396590232849121\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.0612304210662842\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.2164543867111206\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.1063807010650635\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.3950835466384888\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.2210102081298828\n",
            "\n",
            "Epoch number 0\n",
            " Current loss 1.4792771339416504\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.2243778705596924\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.1955878734588623\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.0853077173233032\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.2360670566558838\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 0.9450569152832031\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.3070943355560303\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.293238878250122\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.1515917778015137\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.0776499509811401\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.3024119138717651\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.2333883047103882\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.2689874172210693\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.6479705572128296\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.2838342189788818\n",
            "\n",
            "Epoch number 1\n",
            " Current loss 1.331470012664795\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.1823489665985107\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.2735016345977783\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.239725947380066\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.105751395225525\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.2060288190841675\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.3608794212341309\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 0.9994775056838989\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 0.9616106748580933\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.1146295070648193\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.2598979473114014\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.1448142528533936\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.057124137878418\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.2010765075683594\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.677614450454712\n",
            "\n",
            "Epoch number 2\n",
            " Current loss 1.2920970916748047\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.59258234500885\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.461405634880066\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.4620556831359863\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.2232491970062256\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.476902723312378\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.0418378114700317\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.2995080947875977\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.306201457977295\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.176241159439087\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.2047557830810547\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.134439468383789\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.6606460809707642\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.4911432266235352\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 1.1985044479370117\n",
            "\n",
            "Epoch number 3\n",
            " Current loss 0.9831412434577942\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.3987135887145996\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.486058235168457\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.1765995025634766\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.1905559301376343\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.2425042390823364\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.0355188846588135\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.5117323398590088\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 0.9993283748626709\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.3273935317993164\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.1584904193878174\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.25592839717865\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 0.8650246858596802\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.1692252159118652\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.2902913093566895\n",
            "\n",
            "Epoch number 4\n",
            " Current loss 1.1868102550506592\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.2094709873199463\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.6333504915237427\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.2330260276794434\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.1175932884216309\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.2787189483642578\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 0.8731834888458252\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.1545705795288086\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.1933598518371582\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.1455377340316772\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.5411412715911865\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.1470609903335571\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.2283358573913574\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.1892772912979126\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.1220247745513916\n",
            "\n",
            "Epoch number 5\n",
            " Current loss 1.4144909381866455\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.1783862113952637\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.2332453727722168\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.3845515251159668\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 0.9756684303283691\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.2385544776916504\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.533768892288208\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.2120003700256348\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.1650927066802979\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.1862791776657104\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.13662850856781\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.0733513832092285\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.172492265701294\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.0712692737579346\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.1397218704223633\n",
            "\n",
            "Epoch number 6\n",
            " Current loss 1.3375924825668335\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.210669755935669\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.2117369174957275\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.147897481918335\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.419712781906128\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.1737391948699951\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.3259323835372925\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.139021396636963\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.1005645990371704\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.5747663974761963\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.0454246997833252\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.3150079250335693\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.277604103088379\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.1631999015808105\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.1957237720489502\n",
            "\n",
            "Epoch number 7\n",
            " Current loss 1.389660358428955\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.4132471084594727\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.1389309167861938\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.1169850826263428\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.1723930835723877\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.0228204727172852\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.1759390830993652\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.3251285552978516\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.353884220123291\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.1180400848388672\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.3235256671905518\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.1852991580963135\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.3009767532348633\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.2399499416351318\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.149549961090088\n",
            "\n",
            "Epoch number 8\n",
            " Current loss 1.2626609802246094\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.257676362991333\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.4010956287384033\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.195859670639038\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.342418909072876\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.3210232257843018\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.4541575908660889\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.1638590097427368\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.1518638134002686\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 0.9502888321876526\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.181462287902832\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.6815499067306519\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.0716893672943115\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.2495081424713135\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.199628472328186\n",
            "\n",
            "Epoch number 9\n",
            " Current loss 1.1902563571929932\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.1799492835998535\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.0531761646270752\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.0067470073699951\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.366004228591919\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.1138219833374023\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.2473030090332031\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.2010345458984375\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.4948458671569824\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.2095847129821777\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.252638339996338\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.186557650566101\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.3326051235198975\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.056498646736145\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.3105297088623047\n",
            "\n",
            "Epoch number 10\n",
            " Current loss 1.0784753561019897\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.0399609804153442\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.115102767944336\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.2733267545700073\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.2190983295440674\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.074293613433838\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.3030948638916016\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.2159490585327148\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.1679078340530396\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.1869715452194214\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.0087108612060547\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.2312356233596802\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.221032738685608\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.0412553548812866\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.055426836013794\n",
            "\n",
            "Epoch number 11\n",
            " Current loss 1.2216639518737793\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.4121675491333008\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 0.8584468364715576\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.3650630712509155\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.0622036457061768\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.2138699293136597\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 0.989404022693634\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.2162014245986938\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.1906368732452393\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.241072654724121\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.0455598831176758\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.3616548776626587\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.2110315561294556\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.2675838470458984\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.0853086709976196\n",
            "\n",
            "Epoch number 12\n",
            " Current loss 1.2683018445968628\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.1573323011398315\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 0.9961323738098145\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.2599315643310547\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.1558653116226196\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.261686086654663\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.2250397205352783\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.234526515007019\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.3053264617919922\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.1451375484466553\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.2743480205535889\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.17128324508667\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.2370600700378418\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.3559982776641846\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.2964582443237305\n",
            "\n",
            "Epoch number 13\n",
            " Current loss 1.839296579360962\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.2016218900680542\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 0.9993292689323425\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.038590908050537\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.0389432907104492\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 0.9588523507118225\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.2756080627441406\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.2319092750549316\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.1074104309082031\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.3156087398529053\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.0536465644836426\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.291183352470398\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.2163774967193604\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.1499429941177368\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.2326240539550781\n",
            "\n",
            "Epoch number 14\n",
            " Current loss 1.3583166599273682\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.1608595848083496\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.4662625789642334\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.172886848449707\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.5872315168380737\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.3550786972045898\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.1592575311660767\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.0136823654174805\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.319610595703125\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.2264868021011353\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.1707565784454346\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.2529231309890747\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.332732915878296\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.1834948062896729\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 1.1576566696166992\n",
            "\n",
            "Epoch number 15\n",
            " Current loss 0.9789207577705383\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.2499313354492188\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.3147492408752441\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 0.8714866638183594\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.264137864112854\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.0955791473388672\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.2170276641845703\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 0.9789109230041504\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.183184027671814\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.246462345123291\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.192785382270813\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.3855934143066406\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.4622290134429932\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.1372385025024414\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.1693708896636963\n",
            "\n",
            "Epoch number 16\n",
            " Current loss 1.1883337497711182\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.0308024883270264\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.183034896850586\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.288043737411499\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.1750428676605225\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.1679048538208008\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.5381520986557007\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.1722291707992554\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.2034471035003662\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.1984508037567139\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 0.9580681324005127\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.2535381317138672\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.169270396232605\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.114135980606079\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 0.8106613159179688\n",
            "\n",
            "Epoch number 17\n",
            " Current loss 1.1906421184539795\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.2863805294036865\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.2535581588745117\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.1328661441802979\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.3921856880187988\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.2160449028015137\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.219667673110962\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.03840970993042\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.3226547241210938\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.2503962516784668\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.3877978324890137\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.3719613552093506\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.165062427520752\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.300959825515747\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.2181951999664307\n",
            "\n",
            "Epoch number 18\n",
            " Current loss 1.1564997434616089\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.0826177597045898\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.030343770980835\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.2133339643478394\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.156177282333374\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.298966884613037\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.0138707160949707\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.280487298965454\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.1710253953933716\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.2869737148284912\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.221885085105896\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.1499865055084229\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.0375972986221313\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.0583336353302002\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.128947138786316\n",
            "\n",
            "Epoch number 19\n",
            " Current loss 1.0993609428405762\n",
            "\n",
            "Model Saved Successfully\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCg8Nchbu5VA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}